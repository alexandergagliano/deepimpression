{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0645514e-8752-401b-b0e2-5378b750fc8e",
   "metadata": {},
   "source": [
    "## 08/31/2023\n",
    "\n",
    "Transformer taken from:\n",
    "https://keras.io/examples/timeseries/timeseries_transformer_classification/\n",
    "\n",
    "FREEZE STATE - THIS IS THE BEST PERFORMANCE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "473cd7a1-be55-4a5c-8eb8-a9a90c9aa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras.callbacks import (\n",
    "    CSVLogger,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import time\n",
    "from astronet.t2.model import T2Model\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a1812b-815e-4fac-99ed-f8dbe8549bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6593a66b-45cb-4396-b4f6-aae2d5fb5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try with my own data \n",
    "#only using the 100GP model so that we don't have to use padding, otherwise we would use 0pt2GP.\n",
    "dir = '/Users/alexgagliano/Documents/Research/HostClassifier/transformer/ZTF_Data/'\n",
    "X_train = np.load(dir + 'X_train_ZTF_Obs_FullSliced_Padded_100GP_hostPhotTrue_30Cut.npz')['arr_0']\n",
    "X_test = np.load(dir + 'X_test_ZTF_Obs_FullSliced_Padded_100GP_hostPhotTrue_30Cut.npz')['arr_0']\n",
    "y_train = np.load(dir + 'y_train_ZTF_Obs_FullSliced_Padded_100GP_hostPhotTrue_30Cut.npz')['arr_0']\n",
    "y_test = np.load(dir + 'y_test_ZTF_Obs_FullSliced_Padded_100GP_hostPhotTrue_30Cut.npz')['arr_0']\n",
    "\n",
    "#remove the fits with only 4 or fewer datapoints\n",
    "#x_train_GP = [X_train[x, :, 0][5] != 0 for x in np.arange(len(X_train))]\n",
    "#x_test_GP = [X_test[x, :, 0][5] != 0 for x in np.arange(len(X_test))]\n",
    "\n",
    "#X_train = X_train[x_train_GP]\n",
    "#X_test = X_test[x_test_GP]\n",
    "#y_train = y_train[x_train_GP]\n",
    "#y_test = y_test[x_test_GP]\n",
    "\n",
    "params = {}\n",
    "params['class_weight'] = {0:2, 1:1, 2:5} #weighting the classes\n",
    "#params['class_weight'] = {0:1, 1:1, 2:1} #weighting the classes\n",
    "\n",
    "#only weighting in time \n",
    "weights = np.ones(np.shape(X_train[:, :, 0]))\n",
    "weights[(X_train[:, :, 0][:, -1] < 3)] = 10\n",
    "weights[(X_train[:, :, 0][:, -1] > 3) & (X_train[:, :, 0][:, -1] < 15)] = 5\n",
    "\n",
    "weights[y_train == 0] *= params['class_weight'][0]\n",
    "weights[y_train == 1] *= params['class_weight'][1]\n",
    "weights[y_train == 2] *= params['class_weight'][2]\n",
    "\n",
    "#compress -- not doing time-distributed network\n",
    "weights = weights[:, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a2e62-4635-436d-88f9-9dc481bf3d46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#binarize labels \n",
    "y_train = OneHotEncoder(max_categories=3, sparse_output=False).fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = OneHotEncoder(max_categories=3, sparse_output=False).fit_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "params['num_classes'] = y_train.shape[1]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "params['batch_size'] = 64\n",
    "params['epochs'] = 200\n",
    "# using the optimal parameters here\n",
    "params['filters']= 50\n",
    "params['ff_dim'] = 32\n",
    "params['embed_dim'] = 32\n",
    "params['num_layers'] = 4\n",
    "params['num_heads'] = 2\n",
    "params['droprate'] = 0.28\n",
    "# --> Number of filters to use in ConvEmbedding block, should be equal to embed_dim\n",
    "params['num_filters'] = params['embed_dim']\n",
    "params['passbands'] = 'XY'\n",
    "\n",
    "ts = int(time.time())\n",
    "outputfn = '100GP_Transformer_FullObsReTraining_OptParams_wWeight'\n",
    "outputdir = '/Users/alexgagliano/Documents/Research/HostClassifier/transformer/'\n",
    "textPath = outputdir + '/text/'\n",
    "textfile = open(textPath + \"/\" + outputfn + \"_%s_Transformer_%s.txt\"%(ts, params['passbands']), \"at\")\n",
    "\n",
    "(\n",
    "    _,\n",
    "    timesteps,\n",
    "    num_features,\n",
    ") = X_train.shape  # X_train.shape[1:] == (TIMESTEPS, num_features)\n",
    "input_shape = (params['batch_size'], timesteps, num_features)\n",
    "params['input_shape'] = input_shape\n",
    "\n",
    "model = T2Model(\n",
    "    input_dim=params['input_shape'],\n",
    "    embed_dim=params['embed_dim'],\n",
    "    num_heads=params['num_heads'],\n",
    "    ff_dim=params['ff_dim'],\n",
    "    num_filters=params['num_filters'],\n",
    "    num_classes=params['num_classes'],\n",
    "    num_layers=params['num_layers'],\n",
    "    droprate=params['droprate'],\n",
    ")\n",
    "\n",
    "params['learning_rate'] = 5.e-4\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=params['learning_rate'])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"acc\"])\n",
    "model.load_weights(outputdir+'/models/Model_100GP_Transformer_FullSimTraining_OptParams_noWeight_CheckpointWeights.sav')\n",
    "\n",
    "\n",
    "mc = ModelCheckpoint(outputdir+'/models/Model_%s_CheckpointWeights.sav'%outputfn, monitor='val_loss', mode='min', verbose=1, save_weights_only=True, save_best_only=True, sample_weight=weights)\n",
    "es = EarlyStopping(min_delta=0.001, mode=\"min\", monitor=\"val_loss\", patience=20, restore_best_weights=True,verbose=1)\n",
    "rlrop = ReduceLROnPlateau(cooldown=5, factor=0.5, mode=\"min\", monitor=\"val_loss\", patience=10, verbose=1)\n",
    "\n",
    "#write out model configuration to text file \n",
    "for key in params.keys():\n",
    "    textfile.write(\"{} = {}\\n\".format(key, params[key]))\n",
    "    \n",
    "with redirect_stdout(textfile):\n",
    "    _ = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=params['epochs'],\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[mc, es], verbose=2)\n",
    "    \n",
    "    model.build_graph(params['input_shape'])\n",
    "    \n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f4fe4-5af9-489e-9369-7e9f657561e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = model.encoder.layers[0].att(X_train[0:32, :, :].transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3bbeea-eaad-421c-9cf4-865619ee66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(outputdir+'/models/Model_%s_CheckpointWeights.sav'%outputfn)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ef40d-0f11-417a-8d9a-19ef75af27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the results as a function of phase \n",
    "y_test = y_test.argmax(axis=1)\n",
    "\n",
    "X_test_first3 = X_test[np.nanmax(X_test[:, :, 0], axis=1) < 3, :, :]\n",
    "y_test_first3 = y_test[np.nanmax(X_test[:, :, 0], axis=1) < 3]\n",
    "\n",
    "X_test_mid15 = X_test[(np.nanmax(X_test[:, :, 0], axis=1) >3) & (np.nanmax(X_test[:, :, 0], axis=1) < 15), :, :]\n",
    "y_test_mid15 = y_test[(np.nanmax(X_test[:, :, 0], axis=1) >3) & (np.nanmax(X_test[:, :, 0], axis=1) < 15)]\n",
    "\n",
    "\n",
    "X_test_last15 = X_test[np.nanmax(X_test[:, :, 0], axis=1) > 15, :, :]\n",
    "y_test_last15 = y_test[np.nanmax(X_test[:, :, 0], axis=1) > 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a17d2b-8d29-4591-884f-c903090df1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### calculating statistics ######################\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    f1 = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        f1.append(sklearn.metrics.f1_score(y[test],  np.argmax(model.predict(X[test]), axis=1), average='macro'))\n",
    "    nanmed = np.nanmedian(f1)\n",
    "    nanstd = np.nanstd(f1)\n",
    "    print(\"f1: %.2f +/- %.2f\"%(nanmed, nanstd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d7016-0aa2-49a0-be0c-9b0da0a2c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced auroc score\n",
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    auroc = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        auroc.append(sklearn.metrics.roc_auc_score(y[test],  model.predict(X[test]), average='macro', multi_class='ovr'))\n",
    "    print(np.nanmedian(auroc))\n",
    "    print(np.nanstd(auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ab2bd-6d70-405f-982c-311ebf2a00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced precision:\n",
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    prec = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        prec.append(sklearn.metrics.precision_score(y[test],  np.argmax(model.predict(X[test]), axis=1), average='macro'))\n",
    "    print(np.nanmedian(prec))\n",
    "    print(np.nanstd(prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e3035-50f9-4891-bf28-099d21ccdb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recall\n",
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    rec = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        rec.append(sklearn.metrics.recall_score(y,  np.argmax(model.predict(X), axis=1), average='macro'))\n",
    "    print(np.nanmedian(rec))\n",
    "    print(np.nanstd(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa95e1-f173-4779-8022-5f3bb6c4e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced accuracy:\n",
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    bacc = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        bacc.append(sklearn.metrics.balanced_accuracy_score(y[test],  np.argmax(model.predict(X[test]), axis=1)))\n",
    "    print(np.nanmedian(bacc))\n",
    "    print(np.nanstd(bacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba8c91-d2bc-4a3f-a952-7c7a8af4ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in [(X_test_first3, y_test_first3), (X_test_mid15, y_test_mid15), (X_test_last15, y_test_last15)]:\n",
    "    acc = []\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "    for train,test in cv.split(X, y):\n",
    "        acc.append(sklearn.metrics.accuracy_score(y[test],  np.argmax(model.predict(X[test]), axis=1)))\n",
    "    print(np.nanmedian(acc))\n",
    "    print(np.nanstd(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c59657-e046-46b0-9527-2e8f69acd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PR_wCV(model, params, ax, X, y, encoding_dict, fnstr='', plotpath='./', save=True):\n",
    "    \"\"\"Short summary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : type\n",
    "        Description of parameter `model`.\n",
    "    ax : type\n",
    "        Description of parameter `ax`.\n",
    "    X : type\n",
    "        Description of parameter `X`.\n",
    "    y : type\n",
    "        Description of parameter `y`.\n",
    "    encoding_dict : type\n",
    "        Description of parameter `encoding_dict`.\n",
    "    fnstr : type\n",
    "        Description of parameter `fnstr`.\n",
    "    save : type\n",
    "        Description of parameter `save`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    nsplit = 5\n",
    "    cv = StratifiedKFold(n_splits=nsplit)\n",
    "    classes = np.unique(y)\n",
    "    colors = sns.color_palette('Dark2', params['Nclass'])\n",
    "    mean_r = np.linspace(0, 1, 100)\n",
    "    accuracy_tot = 0\n",
    "    nclass = len(classes)\n",
    "    for j in range(nclass):\n",
    "        ps = []\n",
    "        allAcc = []\n",
    "        aucs = []\n",
    "        all_confMatrices = []\n",
    "        for train, test in cv.split(X, y):\n",
    "            Xtrain_resampled = X[train]\n",
    "            ytrain_resampled = y[train]\n",
    "\n",
    "            probas_ = model.predict(X[test])#[0]\n",
    "            predictions = model.predict(X[test])#[0]\n",
    "            predictDF = pd.DataFrame(data=predictions, columns=classes)\n",
    "            predictions = predictDF.idxmax(axis=1)\n",
    "            precision, recall, thresholds = precision_recall_curve(y[test], probas_[:, j], pos_label=classes[j])\n",
    "            ps.append(interp(mean_r, recall[::-1], precision[::-1]))\n",
    "            pr_auc = auc(recall, precision)\n",
    "            aucs.append(pr_auc)\n",
    "            tempAccuracy =  np.sum(predictions == y[test])/len(y[test])*100\n",
    "            allAcc.append(tempAccuracy)\n",
    "            matr = confusion_matrix(y[test], predictions, normalize='true')\n",
    "            all_confMatrices.append(matr)\n",
    "            accuracy_tot += tempAccuracy\n",
    "        mean_p = np.mean(ps, axis=0)\n",
    "        mean_auc = auc(mean_r, mean_p)\n",
    "        std_auc = np.std(aucs)\n",
    "        accuracy = accuracy_tot / (nsplit*len(classes))\n",
    "        if std_auc < 0.01:\n",
    "            ax.plot(mean_r, mean_p, color=colors[j],\n",
    "                     label='%s (%0.2f $\\pm$ <0.01)' % (encoding_dict[j].replace(\"SN\", \"\"), mean_auc),\n",
    "                     lw=2, alpha=.8)\n",
    "        else:\n",
    "            ax.plot(mean_r, mean_p, color=colors[j],\n",
    "                     label='%s (%0.2f $\\pm$ %0.2f)' % (encoding_dict[j].replace(\"SN\", \"\"), mean_auc, std_auc),\n",
    "                     lw=2, alpha=.8)\n",
    "        std_p = np.std(ps, axis=0)\n",
    "        ps_upper = np.minimum(mean_p + std_p, 1)\n",
    "        ps_lower = np.maximum(mean_p - std_p, 0)\n",
    "        ax.fill_between(mean_r, ps_lower, ps_upper, color=colors[j], alpha=.3)\n",
    "\n",
    "    ax.set_xlabel(\"Precision\");\n",
    "    ax.set_ylabel(\"Recall\");\n",
    "    ax.legend()\n",
    "    #ax.legend(loc=4)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    if save:\n",
    "        plt.savefig(plotpath + \"/Combined_MeanPR_Curve_%s.png\"% fnstr, dpi=150)\n",
    "    return accuracy, allAcc\n",
    "\n",
    "\n",
    "def plot_ROC_wCV(model, params, ax, X, y, encoding_dict, fnstr='', plotpath='./', save=True):\n",
    "    \"\"\"Short summary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : type\n",
    "        Description of parameter `model`.\n",
    "    ax : type\n",
    "        Description of parameter `ax`.\n",
    "    X : type\n",
    "        Description of parameter `X`.\n",
    "    y : type\n",
    "        Description of parameter `y`.\n",
    "    encoding_dict : type\n",
    "        Description of parameter `encoding_dict`.\n",
    "    fnstr : type\n",
    "        Description of parameter `fnstr`.\n",
    "    save : type\n",
    "        Description of parameter `save`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    nsplit = 5\n",
    "    cv = StratifiedKFold(n_splits=nsplit)\n",
    "    classes = np.unique(y)\n",
    "    colors = sns.color_palette('Dark2', params['Nclass'])\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    accuracy_tot = 0\n",
    "    nclass = len(classes)\n",
    "    for j in range(nclass):\n",
    "        wrong = []\n",
    "        allRight = []\n",
    "        tprs = []\n",
    "        allAcc = []\n",
    "        aucs = []\n",
    "        all_confMatrices = []\n",
    "        for train, test in cv.split(X, y):\n",
    "            Xtrain_resampled = X[train]\n",
    "            ytrain_resampled = y[train]\n",
    "\n",
    "            probas_ = model.predict(X[test])#[0]\n",
    "            predictions = model.predict(X[test])\n",
    "            predictDF = pd.DataFrame(data=predictions, columns=classes)\n",
    "            predictions = predictDF.idxmax(axis=1)\n",
    "            fpr, tpr, thresholds = roc_curve(y[test], probas_[:, j], pos_label=classes[j])\n",
    "            tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "            tprs[-1][0] = 0.0\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            aucs.append(roc_auc)\n",
    "            tempAccuracy =  np.sum(predictions == y[test])/len(y[test])*100\n",
    "            allAcc.append(tempAccuracy)\n",
    "            matr = confusion_matrix(y[test], predictions, normalize='true')\n",
    "            all_confMatrices.append(matr)\n",
    "            accuracy_tot += tempAccuracy\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "        accuracy = accuracy_tot / (nsplit*len(classes))\n",
    "        if std_auc < 0.01:\n",
    "            ax.plot(mean_fpr, mean_tpr, color=colors[j],\n",
    "                     label='%s (%0.2f $\\pm$ <0.01)' % (encoding_dict[j].replace(\"SN\", \"\"), mean_auc),\n",
    "                     lw=2, alpha=.8)\n",
    "        else:\n",
    "            ax.plot(mean_fpr, mean_tpr, color=colors[j],\n",
    "                     label='%s (%0.2f $\\pm$ %0.2f)' % (encoding_dict[j].replace(\"SN\", \"\"), mean_auc, std_auc),\n",
    "                     lw=2, alpha=.8)\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[j], alpha=.3)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k',alpha=.8)\n",
    "    ax.set_xlabel(\"False Positive Rate\");\n",
    "    ax.set_ylabel(\"True Positive Rate\");\n",
    "    ax.legend()\n",
    "    #ax.legend(loc=4)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "    if save:\n",
    "        plt.savefig(plotpath + \"/Combined_MeanROC_Curve_%s.png\"% fnstr,dpi=150)\n",
    "    return accuracy, allAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fe170-d6f4-4c48-af87-291b8ad18ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, confusion_matrix\n",
    "from numpy import interp\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "outdir = '/Users/alexgagliano/Documents/Research/HostClassifier/transformer/'\n",
    "params = {'Nclass':3}\n",
    "encoding_dict = {0:'SN II', 1:'SN Ia', 2:'SN Ibc'}\n",
    "\n",
    "######### ROC curves ################\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_ROC_wCV(model, params, fig.gca(), X_test_first3, y_test_first3, encoding_dict, fnstr=outputfn + \"_First3\", plotpath=outdir+'/plots/', save=True)\n",
    "\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_ROC_wCV(model, params, fig.gca(), X_test_mid15, y_test_mid15, encoding_dict, fnstr=outputfn + \"_Mid15\", plotpath=outdir+'/plots/', save=True)\n",
    "\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_ROC_wCV(model, params, fig.gca(), X_test_last15, y_test_last15, encoding_dict, fnstr=outputfn + \"_Last15\", plotpath=outdir+'/plots/', save=True)\n",
    "\n",
    "######### Precision-recall curves ################\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_PR_wCV(model, params, fig.gca(), X_test_first3, y_test_first3, encoding_dict, fnstr=outputfn + \"_First3\", plotpath=outdir+'/plots/', save=True)\n",
    "\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_PR_wCV(model, params, fig.gca(), X_test_mid15, y_test_mid15, encoding_dict, fnstr=outputfn + \"_Mid15\", plotpath=outdir+'/plots/', save=True)\n",
    "\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (8, 8))\n",
    "plot_PR_wCV(model, params, fig.gca(), X_test_last15, y_test_last15, encoding_dict, fnstr=outputfn + \"_Last15\", plotpath=outdir+'/plots/', save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iaifi_summerschool",
   "language": "python",
   "name": "iaifi_summerschool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
